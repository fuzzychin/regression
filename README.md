# Regression

Used to predict the value of a variable given another variable

With linear regression we are calculating the MEAN value of y for a given value of x

response variable - explanatory variable
dependent variable - independent variable

y axis - dependent variable  
x axis - independent variableÂ 

Least squares - sum of all the squared deviations is smallest.  We square the deviations because some are positive and some are negative

Extrapolation - trying to predict values of Y for values of X outside the range of X

Null Hypothesis - there is no linear relationship
Alternative Hypothesis - a linear relationship exists

## Key elements of model summary

Null Hypothesis - independent variable has no effect on dependent variable (slope = 0)

Coefficient - slope

P Value - statistical significance - results didn't happen by chance.
P Value > 0.05 means results are not statistically significant and we cannot reject the null hypothesis

R2 - measures the fit of the line to the data.
R2 = 1 means x predicts all values of y.
Conversely, R2 = 0 means x predicts no values of y
So if R2 = .80, that means that, in our model, 80% of the values of x explain value of y
However, as you add more variables, R2 will always go up.  The Adjusted R2 accounts for this.
